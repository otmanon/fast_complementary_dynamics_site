<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
	<meta charset="utf-8"/>
	<title>Fast Complementary Dynamics</title>
	<meta name="author" content="Otman Benchekroun, Jiayi Eris Zhang, Siddhartha Chaudhuri, Eitan Grinspun, Yi Zhou, Alec Jacobson"/>
  <link type="text/css" rel="stylesheet" href="style.css"/>
</head>
<body>
<h1 id="complementarydynamics_siggraphasia2020_" style="font-size:32px;"> Fast Complementary Dynamics via Skinning Eigenmodes</h1>

<h1>  Otman Benchekroun<sup>1</sup>, Jiayi Eris Zhang<sup>2</sup>, Siddhartha Chaudhuri<sup>3</sup>, <br> Eitan Grinspun<sup>1</sup>, Yi Zhou<sup>3</sup>, Alec Jacobson <sup>1, 3</sup></h1>

<h2 style="text-align:center;"> <sup>1</sup>University of Toronto , <sup>2</sup>Stanford University, <sup>3</sup>Adobe Research</h1>
<h1 > <em>SIGGRAPH North America 2023</em></h1>

<div style="text-align: center;">
<video width=80% height=80%  muted autoplay loop preload> 
  <source  src="aquarium.mp4" > 
</video>
</div>

<h1 id="abstract" style="text-align:left">Abstract</h1>
<p> 
  We propose a reduced-space elasto-dynamic solver that 
  is well suited for augmenting rigged character
   animations with secondary motion. At the core 
   of our method is a novel deformation subspace based on 
   Linear Blend Skinning that overcomes many of the shortcomings
    prior subspace methods face. Our skinning subspace is parameterized 
    entirely by a set of scalar weights, which we can obtain through 
    a small, material-aware and rig-sensitive generalized eigenvalue problem. 
    The resulting subspace can easily capture rotational motion and 
    guarantees that the resulting simulation is rotation equivariant. 
    We further propose a simple local-global solver for linear co-rotational 
    elasticity and propose a clustering method to aggregate per-tetrahedra 
    non-linear energetic quantities. The result is a compact simulation 
    that is fully decoupled from the complexity of the mesh.
</p>

<h1 id="downloads" style="text-align:left">Downloads</h1>
<ul>
<li> <a href="./Fast_Complementary_Dynamics.pdf">Paper (100 MB)</a></li>
<li> <a href="./Fast_Complementary_Dynamics_Low_res.pdf">Paper (10 MB)</a></li>
<li> <a href="./supplemental-video.mp4">Supplementary Video</a></li>
<li> <a href="./fast-forward.mp4">Fast Forward Video</a></li>
</ul>

<h1 id="bibtex" style="text-align:left">Bibtex</h1>
<pre><code>@article{benchekroun2023FastComplemDynamics,
  title = {Fast Complementary Dynamics via Skinning Eigenmodes},
  author = {Otman Benchekroun, Jiayi Eris Zhang, Siddhartha Chaudhuri, Eitan Grinspun, Yi Zhou, Alec Jacobson},
  year = {2023},
  journal = {ACM Transactions on Graphics},
}
</code></pre>


<h1 style="text-align:left">Summary</h1>

<div style="text-align: center;">
  <video width=50% height=50%  muted autoplay loop preload> 
    <source  src="fast-forward.mp4" > 
  </video>
  </div>
<p style="text-align: center;"> We add secondary motion to rig animations in real-time by using a subspace for the physics simulation.</p>

<div>
  <br>
      <p style="text-align:center; margin-right:15%;">We propose a linear blend skinning-like subspace for secondary motion. 
          Our subspace is fully parameterized by a set of skinning weights, which are found 
      via an eigen-decomposition of the elastic energy Laplacian</p>
      
      
  <div style="text-align: center;">
    <video width=50% height=50%  muted autoplay loop preload> 
      <source  src="videos/charizard-skinning-modes.mp4">
    </video>
    </div>
     

      <p style="text-align:center; margin-right:15%;">
          With a simple modification to the elastic energy Laplacian, 
          our skinning eigenmodes can be made rig-aware, and satisfy the rig-orthogonality constraint inherently</p>
      
    
      <div style="text-align: center;">
        <video width=50% height=50%  muted autoplay loop preload> 
          <source src="videos/charizard-skinning-modes-comp.mp4"> 
        </video>
        </div>
         
      <p style="text-align:center; margin-right:15%;">
      To accelerate computation of energetic non-linearities in our simulation, we extend our skinning modes with
      skinning clusters. Our clusters reflect the rig-awareness of our skinning weights</p>

      
      <figure style="text-align: center;">
          <img src="videos/clusters.png" width="100%"/>
      </figure>
</div>


<p style="text-align:center; margin-right:15%; font-size:16px;">
<strong> IK Chicken</strong>
</p >

<div style="text-align: center;">
  <video width=50% height=50%  muted autoplay loop preload controls> 
    <source src="videos/ikcd.mp4"> 
  </video>
  </div>



<p style="text-align:center; margin-right:15%; font-size:16px;">
  <strong>Pose Tracking </strong>
  </p >

  <div style="text-align: center;">
    <video width=50% height=50%  muted autoplay loop preload controls> 
      <source  src="videos/pose-tracking.mp4"> 
    </video>
    </div>

<p style="text-align:center; margin-right:15%; font-size:16px;">
  <strong> Face Tracking </strong>
</p >

<div style="text-align: center;">
  <video width=50% height=50%  muted autoplay loop preload controls> 
    <source src="videos/face-tracking.mp4"> 
  </video>
  </div>
<p style="text-align:center; margin-right:15%; font-size:16px;">
 <strong>Interactive Aquarium</strong> 
</p >

<div style="text-align: center;">
  <video width=50% height=50%  muted autoplay loop preload controls> 
    <source src="videos/Interactiveaquarium.mp4"> 
  </video>
  </div>
      

<h1  style="text-align:left">Acknowledgements</h1>

<p>
  This project is funded in part by NSERC Discovery (RGPIN2017–05235,
  RGPIN-2021-03733,
  RGPAS–2017–507938) New Frontiers of Research Fund (NFRFE–201),
  the Ontario Early Research Award program, the Canada Research
  Chairs Program, a Sloan Research Fellowship, the DSI Catalyst Grant program and gifts by Adobe Inc. Otman Benchekroun was funded by an NSERC CGS-M scholarship, while Jiayi Eris Zhang is funded by a Stanford Graduate Fellowship.
  We thank David I.W. Levin, Danny M. Kaufman, Doug L. James, Ty Trusty, Sarah Kushner and Silvia Sellán for insightful conversations. We thank Alejandra Baptista Aguilar for early discussion and adoption in 3D environments, and for providing some of the models in the paper. We thank Silvia Sellán, Selena Ling, Shukui Chen, Aravind Ramakrishnan and Kinjal Parikh for proofreading.  We thank Xuan Dam and John Hancock for technical and administrative assistance throughout the course of this project.
</p>

</body>
</html>

